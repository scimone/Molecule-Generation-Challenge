{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MoleculeGeneration_(2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9e1YQ3yst3C"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_HEqxgaaQ_v",
        "outputId": "229daeaa-b00e-43d7-b736-c35ae572055a"
      },
      "source": [
        "!pip install kora -q\n",
        "import kora.install.rdkit\n",
        "!pip install deepchem\n",
        "!pip install fcd\n",
        "!pip install SmilesPE"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▊                          | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 29.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 28.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40kB 19.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[?25hCollecting deepchem\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/01/0eb8ffcb25826af32ca6efcf624206ef95825ffb00a12e2db802cc0a0b22/deepchem-2.5.0-py3-none-any.whl (552kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.5.0\n",
            "Collecting fcd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/1d/75bf35ec742cbe679bfe373e5a0859a1debbd1bcc15d3cfa0930620438b2/FCD-1.1-py3-none-any.whl (53.1MB)\n",
            "\u001b[K     |████████████████████████████████| 53.1MB 86kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fcd) (1.19.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from fcd) (2.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fcd) (1.4.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from fcd) (2.5.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->fcd) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->fcd) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.15.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (2.5.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (0.2.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (0.4.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.34.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.6.3)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras->fcd) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->fcd) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->fcd) (1.30.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->fcd) (56.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->fcd) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->fcd) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->fcd) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->fcd) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->fcd) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->fcd) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->fcd) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->fcd) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->fcd) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->fcd) (4.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->fcd) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->fcd) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->fcd) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->fcd) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->fcd) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->fcd) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow->fcd) (3.4.1)\n",
            "Installing collected packages: fcd\n",
            "Successfully installed fcd-1.1\n",
            "Collecting SmilesPE\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/f9/273f54d9d4b42779926291c82a5b3ffea30cff2492ebbe4ce08dccdcc949/SmilesPE-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: fastprogress in /usr/local/lib/python3.7/dist-packages (from SmilesPE) (1.0.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from SmilesPE) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastprogress->SmilesPE) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->SmilesPE) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->SmilesPE) (5.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->SmilesPE) (1.4.1)\n",
            "Installing collected packages: SmilesPE\n",
            "Successfully installed SmilesPE-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDigIiNRa9VH",
        "outputId": "3ee8f94b-69cf-4b67-86d9-81fdb0993168"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import rdkit\n",
        "from SmilesPE.pretokenizer import atomwise_tokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.autograd import Variable\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "# Ignore some warnings from RDKIT\n",
        "from rdkit import RDLogger  \n",
        "RDLogger.DisableLog('rdApp.*') \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load methods from the FCD library\n",
        "from fcd import get_fcd, load_ref_model, canonical_smiles, get_predictions, calculate_frechet_distance\n",
        "\n",
        "np.random.seed(1234)\n",
        "\n",
        "# For CUDA debugging\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "print(\"RDKit: \", rdkit.__version__)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RDKit:  2020.09.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DoeONI286qG",
        "outputId": "53c5bb2b-3197-4889-c4bd-427a1ded312a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqL0fiDqi1Z-"
      },
      "source": [
        "path = '/content/drive/MyDrive/ails_challenge_2/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PbMEbAKlmeL"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o1DNq_CRblP"
      },
      "source": [
        "def plot_metrics(train_errors, valid_errors):\n",
        "  x = np.arange(1, len(train_errors)+1)\n",
        "  fig = plt.figure(figsize=(20,5))\n",
        "  ax = fig.add_subplot(131, label=\"train\")\n",
        "  ax.plot(x, train_errors, color=\"C0\", label=\"training loss\")\n",
        "  ax.plot(x, valid_errors, color=\"C1\", label=\"validation loss\")\n",
        "  ax.set_ylabel(\"Loss\")\n",
        "  ax.set_xlabel(\"Epoch\")        \n",
        "  ax.xaxis.grid(False)  \n",
        "  ax.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GNxLa1dKgLK"
      },
      "source": [
        "def save_checkpoint(model, optimiser, epoch, loss, dictionary):\n",
        "  \"\"\"Saves a model checkpoint\"\"\"\n",
        "  state = {\n",
        "      'epoch': epoch,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimiser_state_dict': optimiser.state_dict(),\n",
        "      'loss': loss,\n",
        "      'dict': dictionary\n",
        "  }\n",
        "  os.makedirs(path + \"checkpoints\", exist_ok=True)\n",
        "  ckp_name = f'checkpoint-epoch{epoch}.pth'\n",
        "  filename = os.path.join(path + \"checkpoints\", ckp_name)\n",
        "  torch.save(state, filename)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "064Z4OlrMTSr"
      },
      "source": [
        "def load_checkpoint(model, optimiser, epoch):\n",
        "  ckp_name = f'checkpoint-epoch{epoch}.pth'\n",
        "  filename = os.path.join(path + \"checkpoints\", ckp_name)\n",
        "\n",
        "  checkpoint = torch.load(filename)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimiser.load_state_dict(checkpoint['optimiser_state_dict'])\n",
        "  loss = checkpoint['loss']\n",
        "  dictionary = checkpoint['dict']\n",
        "  return model, optimiser, loss, dictionary"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezLa5lOqs3G3"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZBQeETOByj4"
      },
      "source": [
        "def load_data(file_path):\n",
        "  with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
        "    data = file.read()\n",
        "  return data\n",
        "\n",
        "def get_dictionary(data, atom):\n",
        "  if atom:\n",
        "    characters = [pad_token, start_token, end_token] + list(set(atomwise_tokenizer(data)))\n",
        "  else:\n",
        "    characters = [pad_token, start_token, end_token] + sorted(list(set(data)))\n",
        "\n",
        "  char2idx = dict((c, i) for i, c in enumerate(characters))\n",
        "  idx2char = dict((i, c) for i, c in enumerate(characters))\n",
        "  dictionary = (char2idx, idx2char)\n",
        "  return dictionary, characters\n",
        "\n",
        "def preprocess(data):  \n",
        "  smiles = data.split() # separate string into distinct smiles molecules\n",
        "  smiles_can = canonical_smiles(smiles)  # canonicalize\n",
        "  smiles_can = list(filter(None, smiles_can))  # filter invalid ones\n",
        "  preprocessed_smiles = add_tokens(smiles_can)\n",
        "  return preprocessed_smiles\n",
        "\n",
        "def add_tokens(smiles):\n",
        "  smiles_new = []\n",
        "  for smile in smiles:\n",
        "    smiles_new.append(start_token + smile + end_token)\n",
        "  return smiles_new\n",
        "\n",
        "def encode(smiles, dictionary, atom):\n",
        "  char2idx = dictionary[0]\n",
        "  if atom:\n",
        "    encoded = []\n",
        "    for smile in smiles:\n",
        "      token = atomwise_tokenizer(smile)\n",
        "      if len(token) > 1:\n",
        "        tokenized = [1]\n",
        "        for s in token:    \n",
        "          tokenized.append(char2idx[s])\n",
        "        tokenized.append(2)\n",
        "        encoded.append(torch.Tensor(tokenized).long())\n",
        "  else:\n",
        "    encoded = [torch.Tensor([char2idx[s] for s in smile]).long() for smile in smiles]\n",
        "  lengths = [len(smile_enc)-1 for smile_enc in encoded]\n",
        "  return encoded, lengths\n",
        "\n",
        "def get_padded_tensor(encoded, n_max):\n",
        "  dummy = [torch.zeros(n_max)]  # to ensure that train and validation get the same padding size\n",
        "  padded = pad_sequence(dummy + encoded, batch_first=True, padding_value=0)\n",
        "  padded = padded[1:]  # omit the dummy\n",
        "  return padded\n",
        "\n",
        "atom = True  # whether to use atomwise tokenizer\n",
        "\n",
        "pad_token = 'x'\n",
        "start_token = 'y'\n",
        "end_token = 'z'\n",
        "\n",
        "data = load_data(path + 'smiles_train.txt')\n",
        "smiles = preprocess(data)\n",
        "dictionary_data = \" \".join(smiles)\n",
        "dictionary, characters = get_dictionary(dictionary_data, atom=atom)\n",
        "\n",
        "n_max = len(max(smiles, key=len))\n",
        "\n",
        "# train test split\n",
        "smiles_train, smiles_val = train_test_split(smiles, test_size=0.3, random_state=42)\n",
        "\n",
        "encoded_train, lengths_train = encode(smiles_train, dictionary, atom=atom)\n",
        "encoded_val, lengths_val = encode(smiles_val, dictionary, atom=atom)\n",
        "\n",
        "tensor_train = get_padded_tensor(encoded_train, n_max)\n",
        "tensor_val = get_padded_tensor(encoded_val, n_max)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTFKEoggnK6j"
      },
      "source": [
        "class Data(Dataset):\n",
        "  def __init__(self, embedded, encoded, lengths):  \n",
        "    self.embedded = embedded\n",
        "    self.encoded = encoded\n",
        "    self.lengths = lengths\n",
        "    self.samples = self.__create_samples() \n",
        "\n",
        "  def __get_tuple(self, idx):\n",
        "    data = self.embedded[idx,:]\n",
        "    x = data[0:-1]\n",
        "    y = data[1:]\n",
        "    len = self.lengths[idx]\n",
        "    return (x, y, len)\n",
        "\n",
        "  def __create_samples(self):\n",
        "    samples = [self.__get_tuple(idx) for idx in range(self.embedded.shape[0])]\n",
        "    return samples\n",
        "        \n",
        "  def __len__(self) -> int:\n",
        "    return len(self.samples)\n",
        "      \n",
        "  def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    return self.samples[idx]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaHQsoEu2r7n"
      },
      "source": [
        "train_set = Data(tensor_train.long(), encoded_train, lengths_train)\n",
        "val_set = Data(tensor_val.long(), encoded_val, lengths_val)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHWcSfUXs94A"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poWslySOuanP"
      },
      "source": [
        "class MoleculeGenerator(nn.Module):\n",
        "  def __init__(self, n_in, n_hidden, n_out, n_seq, n_layers=1, dropout_rate=0.3):\n",
        "    super(MoleculeGenerator, self).__init__()\n",
        "    self.n_hidden = n_hidden\n",
        "    self.n_layers = n_layers\n",
        "    self.n_out = n_out\n",
        "    self.n_seq = n_seq\n",
        "\n",
        "    self.embedding = nn.Embedding(n_out, n_in, padding_idx=0)\n",
        "    self.lstm = nn.LSTM(input_size=n_in, hidden_size=n_hidden, num_layers=n_layers, dropout=dropout_rate, batch_first=True)\n",
        "    self.out = nn.Linear(n_hidden, n_out)\n",
        "\n",
        "  def forward(self, input, hidden, lengths=None):\n",
        "    input = self.embedding(input)\n",
        "    if lengths is not None:\n",
        "      input = pack_padded_sequence(input, lengths, batch_first=True, enforce_sorted=False)\n",
        "    output, hidden = self.lstm(input, hidden)\n",
        "    if lengths is not None:\n",
        "      output, _ = pad_packed_sequence(output, batch_first=True, total_length=self.n_seq)\n",
        "    output = output.contiguous().view(-1, self.n_hidden)\n",
        "    output = self.out(output)\n",
        "    return output, hidden\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden=(Variable(torch.zeros(self.n_layers, batch_size, self.n_hidden)),\n",
        "            Variable(torch.zeros(self.n_layers, batch_size, self.n_hidden)))\n",
        "    return hidden\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb5i-b4usHQT"
      },
      "source": [
        "def get_error(network, dataloader, loss):\n",
        "  for x, y, len in dataloader:\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "    sequence_length = x.size(1)\n",
        "\n",
        "    hidden = network.init_hidden(batch_size)\n",
        "    hidden = (hidden[0].to(device), hidden[1].to(device))\n",
        "    \n",
        "    y_pred, hidden = network(x, hidden, lengths=None)\n",
        "    err = loss(y_pred, y.view(batch_size * sequence_length))\n",
        "    del(x, y)\n",
        "    yield err"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6sRI1Nxv4oK"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(network, loss, dataloader, epoch):\n",
        "\n",
        "  network.eval()\n",
        "  errors = []\n",
        "\n",
        "  with tqdm(get_error(network, dataloader, loss), leave=True, unit=\" batches\", position=0, total=len(dataloader)) as pbar:\n",
        "    n_batches = len(pbar)\n",
        "    for i, err in enumerate(pbar):\n",
        "      pbar.set_description('epoch {}: validation loss {}'.format(epoch, round(err.item(), 4)))\n",
        "      errors.append(err.item())\n",
        "\n",
        "      if i == n_batches-1:\n",
        "        mean_err = sum(errors) / len(errors)\n",
        "        pbar.set_description('epoch {}: mean validation loss {}'.format(epoch, round(mean_err, 4)))\n",
        "  pbar.close()\n",
        "  return mean_err"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBkEeQ-Ks4vI"
      },
      "source": [
        "@torch.enable_grad()\n",
        "def update(network, loss, dataloader, opt, epoch):\n",
        "  network.train()\n",
        "  errors = []\n",
        "\n",
        "  with tqdm(get_error(network, dataloader, loss), leave=True, unit=\" batches\", position=0, total=len(dataloader)) as pbar:\n",
        "    n_batches = len(pbar)\n",
        "    for i, err in enumerate(pbar):\n",
        "      network.zero_grad()\n",
        "      err.backward()\n",
        "      opt.step()\n",
        "\n",
        "      pbar.set_description('epoch {}: training loss {}'.format(epoch, round(err.item(), 4)))\n",
        "      errors.append(err.item())\n",
        "\n",
        "      if i == n_batches-1:\n",
        "        mean_err = sum(errors) / len(errors)\n",
        "        pbar.set_description('epoch {}: mean training loss {}'.format(epoch, round(mean_err, 4)))\n",
        "\n",
        "  pbar.close()\n",
        "  return mean_err"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZMdcDnTlrv2"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSIZtIQvpEEu"
      },
      "source": [
        "# Parameters\n",
        "n_in = len(characters)  # embedding size\n",
        "n_hidden = 1000\n",
        "n_out = len(characters)  # number of characters\n",
        "n_layers = 2\n",
        "batch_size = 256\n",
        "shuffle = True\n",
        "epochs = 21\n",
        "lr = 1e-4\n",
        "n_seq = n_max-1"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tst96rsewS3G",
        "outputId": "89ebf4cd-69f6-48a7-d9ee-180b33a845ca"
      },
      "source": [
        "train_errors = []\n",
        "valid_errors = []\n",
        "\n",
        "# Data\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=shuffle)\n",
        "valid_loader = DataLoader(val_set, batch_size=batch_size)\n",
        "    \n",
        "# Network, Loss and Optimiser\n",
        "network = MoleculeGenerator(n_in, n_hidden, n_out, n_seq, n_layers)\n",
        "network = network.to(device)\n",
        "loss = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimiser = torch.optim.Adam(network.parameters(), lr=lr)  \n",
        "\n",
        "for epoch in range(epochs):\n",
        "  if epoch is 0:\n",
        "    pass  # skip initial validation to speed up training\n",
        "    # train_errors = [evaluate(network, loss.eval(), train_loader, epoch)]\n",
        "    # valid_errors = [evaluate(network, loss.eval(), valid_loader, epoch)]\n",
        "  else:\n",
        "    train_error = update(network, loss, train_loader, optimiser, epoch)\n",
        "    train_errors.append(train_error)\n",
        "    valid_error = evaluate(network, loss.eval(), valid_loader, epoch)\n",
        "    valid_errors.append(valid_error)\n",
        "    save_checkpoint(network, optimiser, epoch, loss, dictionary)  "
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1: mean training loss 1.0143: 100%|██████████| 3481/3481 [11:45<00:00,  4.94 batches/s]\n",
            "epoch 1: mean validation loss 0.7813: 100%|██████████| 1492/1492 [01:50<00:00, 13.53 batches/s]\n",
            "epoch 2: mean training loss 0.7478: 100%|██████████| 3481/3481 [11:45<00:00,  4.94 batches/s]\n",
            "epoch 2: mean validation loss 0.7014: 100%|██████████| 1492/1492 [01:50<00:00, 13.55 batches/s]\n",
            "epoch 3: mean training loss 0.6873: 100%|██████████| 3481/3481 [11:45<00:00,  4.93 batches/s]\n",
            "epoch 3: mean validation loss 0.6566: 100%|██████████| 1492/1492 [01:49<00:00, 13.57 batches/s]\n",
            "epoch 4: mean training loss 0.6496: 100%|██████████| 3481/3481 [11:45<00:00,  4.94 batches/s]\n",
            "epoch 4: mean validation loss 0.6264: 100%|██████████| 1492/1492 [01:49<00:00, 13.58 batches/s]\n",
            "epoch 5: mean training loss 0.622: 100%|██████████| 3481/3481 [11:45<00:00,  4.94 batches/s]\n",
            "epoch 5: mean validation loss 0.6037: 100%|██████████| 1492/1492 [01:50<00:00, 13.52 batches/s]\n",
            "epoch 6: mean training loss 0.6007: 100%|██████████| 3481/3481 [11:45<00:00,  4.93 batches/s]\n",
            "epoch 6: mean validation loss 0.5878: 100%|██████████| 1492/1492 [01:50<00:00, 13.55 batches/s]\n",
            "epoch 7: mean training loss 0.5836: 100%|██████████| 3481/3481 [11:45<00:00,  4.94 batches/s]\n",
            "epoch 7: mean validation loss 0.5728: 100%|██████████| 1492/1492 [01:50<00:00, 13.56 batches/s]\n",
            "epoch 8: mean training loss 0.5694: 100%|██████████| 3481/3481 [11:48<00:00,  4.92 batches/s]\n",
            "epoch 8: mean validation loss 0.5608: 100%|██████████| 1492/1492 [01:49<00:00, 13.58 batches/s]\n",
            "epoch 9: mean training loss 0.5573: 100%|██████████| 3481/3481 [11:49<00:00,  4.91 batches/s]\n",
            "epoch 9: mean validation loss 0.5518: 100%|██████████| 1492/1492 [01:50<00:00, 13.56 batches/s]\n",
            "epoch 10: mean training loss 0.5469: 100%|██████████| 3481/3481 [11:48<00:00,  4.91 batches/s]\n",
            "epoch 10: mean validation loss 0.5441: 100%|██████████| 1492/1492 [01:49<00:00, 13.58 batches/s]\n",
            "epoch 11: mean training loss 0.5378: 100%|██████████| 3481/3481 [11:48<00:00,  4.91 batches/s]\n",
            "epoch 11: mean validation loss 0.5378: 100%|██████████| 1492/1492 [01:50<00:00, 13.51 batches/s]\n",
            "epoch 12: mean training loss 0.5298: 100%|██████████| 3481/3481 [11:50<00:00,  4.90 batches/s]\n",
            "epoch 12: mean validation loss 0.5316: 100%|██████████| 1492/1492 [01:50<00:00, 13.47 batches/s]\n",
            "epoch 13: mean training loss 0.5228: 100%|██████████| 3481/3481 [11:50<00:00,  4.90 batches/s]\n",
            "epoch 13: mean validation loss 0.5277: 100%|██████████| 1492/1492 [01:50<00:00, 13.50 batches/s]\n",
            "epoch 14: mean training loss 0.516: 100%|██████████| 3481/3481 [11:51<00:00,  4.89 batches/s]\n",
            "epoch 14: mean validation loss 0.5227: 100%|██████████| 1492/1492 [01:50<00:00, 13.55 batches/s]\n",
            "epoch 15: mean training loss 0.5102: 100%|██████████| 3481/3481 [11:50<00:00,  4.90 batches/s]\n",
            "epoch 15: mean validation loss 0.5193: 100%|██████████| 1492/1492 [01:50<00:00, 13.55 batches/s]\n",
            "epoch 16: mean training loss 0.5048: 100%|██████████| 3481/3481 [11:50<00:00,  4.90 batches/s]\n",
            "epoch 16: mean validation loss 0.516: 100%|██████████| 1492/1492 [01:50<00:00, 13.56 batches/s]\n",
            "epoch 17: mean training loss 0.4999: 100%|██████████| 3481/3481 [11:50<00:00,  4.90 batches/s]\n",
            "epoch 17: mean validation loss 0.5145: 100%|██████████| 1492/1492 [01:50<00:00, 13.50 batches/s]\n",
            "epoch 18: mean training loss 0.4953: 100%|██████████| 3481/3481 [11:50<00:00,  4.90 batches/s]\n",
            "epoch 18: mean validation loss 0.5107: 100%|██████████| 1492/1492 [01:50<00:00, 13.49 batches/s]\n",
            "epoch 19: mean training loss 0.4911: 100%|██████████| 3481/3481 [11:50<00:00,  4.90 batches/s]\n",
            "epoch 19: mean validation loss 0.5087: 100%|██████████| 1492/1492 [01:50<00:00, 13.51 batches/s]\n",
            "epoch 20: mean training loss 0.4871: 100%|██████████| 3481/3481 [11:50<00:00,  4.90 batches/s]\n",
            "epoch 20: mean validation loss 0.5064: 100%|██████████| 1492/1492 [01:50<00:00, 13.47 batches/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "uR62ezPXtMW4",
        "outputId": "47542993-873e-462d-933f-248a00f2beb9"
      },
      "source": [
        "plot_metrics(train_errors, valid_errors)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JyL6Nw1PziE"
      },
      "source": [
        "# Generate SMILES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gGBFH3eTDKF"
      },
      "source": [
        "Source of generation code: https://medium.com/@sunitachoudhary103/generating-molecules-using-a-char-rnn-in-pytorch-16885fd9394b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1APZP38mFTN"
      },
      "source": [
        "# Declaring a method to generate new text\n",
        "def sample(net, primes, size, dictionary, top_k=None):\n",
        "  net.eval() # eval mode  \n",
        "  hidden = net.init_hidden(1)\n",
        "  char2idx = dictionary[0]\n",
        "\n",
        "  prime = random.sample(primes, 1)[0]\n",
        "  chars = [ch for ch in prime]\n",
        "  x = np.ones((1,1))  # start token\n",
        "  idx, char, hidden = predict(net, x, hidden, dictionary, top_k=top_k)\n",
        "  for ch in atomwise_tokenizer(prime):\n",
        "    x = np.array([[char2idx[ch]]])\n",
        "    idx, char, hidden = predict(net, x, hidden, dictionary, top_k=top_k)\n",
        "  chars.append(char)\n",
        "\n",
        "  # Now pass in the previous character and get a new one\n",
        "  for ii in range(size):\n",
        "      idx = np.expand_dims(np.expand_dims(np.array(idx), axis=0), axis=0)\n",
        "      idx, char, hidden = predict(net, idx, hidden, dictionary, top_k=top_k)\n",
        "      if idx == 2:\n",
        "        break    \n",
        "      chars.append(char)\n",
        "  return ''.join(chars)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ8YemAZdiLk"
      },
      "source": [
        "def predict(net, x, h, dictionary, top_k=None):\n",
        "  ''' Given a character, predict the next character.\n",
        "      Returns the predicted character and the hidden state.\n",
        "  '''\n",
        "  idx2char = dictionary[1]\n",
        "  # tensor inputs\n",
        "  x = torch.from_numpy(x).long()\n",
        "  x = x.to(device)\n",
        "  # detach hidden state from history\n",
        "  h = tuple([each.data.to(device) for each in h])\n",
        "  # get the output of the model\n",
        "  out, h = net(x, h)\n",
        "  p = F.softmax(out, dim=1).data\n",
        "  p = p.cpu() # move to cpu\n",
        "  # get top characters\n",
        "  if top_k is None:\n",
        "      top_ch = np.arange(len(characters))\n",
        "  else:\n",
        "      p, top_ch = p.topk(top_k)\n",
        "      top_ch = top_ch.numpy().squeeze()\n",
        "  # select the likely next character with some element of randomness\n",
        "  p = p.numpy().squeeze()\n",
        "  idx = np.random.choice(top_ch, p=p/p.sum())\n",
        "  # convert idx to char\n",
        "  char = idx2char[idx]\n",
        "  return idx, char, h"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOFUUc5sdm4G"
      },
      "source": [
        "n_smiles = 11000\n",
        "generated_smiles = []\n",
        "\n",
        "# Get prime characters from train data\n",
        "primes = [smile[1:3] for smile in smiles]\n",
        "\n",
        "for i in range(n_smiles):\n",
        "  generated_smiles.append(sample(network, primes, n_max, dictionary, top_k=4))"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvivrFCicb53",
        "outputId": "70b7e9ad-1c22-4adc-dc42-15d5a462f8db"
      },
      "source": [
        "generated_smiles[:10]"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['COc1cc(CC(=O)NCC(=O)NC(Cc2ccccc2)C(=O)NC(C=Cc2ccccc2)C(=O)O)cc(OC)c1OC',\n",
              " 'CCCCCNCC(O)COc1cccc(O)c1',\n",
              " 'CC(=O)OC1CCC2(C)C(CCC3(C)C2C(=O)C=C2C4C(C)C(C)CCC4(C(=O)N4CCN(Cc5ccccc5)CC4)CCC23)CC1(C)C',\n",
              " 'N=C(N)Nc1ccc(C(=O)OCC(=O)NC2CCC(=O)NC2)cc1',\n",
              " 'COC(=O)NC(C(=O)NN(CCC(O)(Cc1ccccc1)C(=O)NC1c2ccccc2CC1O)Cc1ccc(-c2ccsc2)cc1)C(C)(C)C',\n",
              " 'COc1ccc(N(CC(=O)NCCCN2CCN(c3ccccn3)CC2)S(C)(=O)=O)cc1',\n",
              " '[O=C(O)CCCC(=O)Nc1ccc(-c2nc3ccccc3c(=O)[nH]2)cc1',\n",
              " 'Cc1csc(NC(=O)CCNS(=O)(=O)c2ccc(C)cc2)n1',\n",
              " 'COc1cc(C2CCN(C)CC2)ccc1Nc1ncc2c(n1)N(C)c1ccc(Cl)cc1C(=O)N2C',\n",
              " 'Cc1nn(C)c(C)c1N[S+](=O']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQp9ILpUxGEo"
      },
      "source": [
        "# Export valid generated SMILES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w35IUzRkI3HS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089c0f76-f3c1-42d8-fcf5-4d034731a1e2"
      },
      "source": [
        "smiles_gen_can = [w for w in canonical_smiles(generated_smiles) if w is not None]\n",
        "print('Nr of valid smiles: ' + str(len(smiles_gen_can)))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nr of valid smiles: 10469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St9KXpvBQWM-"
      },
      "source": [
        "with open(path + \"submission.txt\", \"w\") as smiles_file:\n",
        "  smiles_file.write(\"\\n\".join(smiles_gen_can))"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSYa0hJy42nJ"
      },
      "source": [
        "# Check Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7ynqUHNeW-o",
        "outputId": "844a2ba7-33e2-4397-d010-2f3f26fb8069"
      },
      "source": [
        "smiles_gen = smiles_gen_can.copy()[:10000]\n",
        "smiles_gen_can = [w for w in canonical_smiles(smiles_gen) if w is not None]\n",
        "\n",
        "# Calculate statistics for the sample submission\n",
        "model = load_ref_model()\n",
        "act_gen = get_predictions(model, smiles_gen_can)\n",
        "mu_gen = np.mean(act_gen, axis=0)\n",
        "sigma_gen = np.cov(act_gen.T)\n",
        "\n",
        "# Load precomputed test mean and covariance\n",
        "with open(path + \"resources/test_stats.p\", 'rb') as f:\n",
        "    mu_test, sigma_test = pickle.load(f)\n",
        "\n",
        "fcd_value = calculate_frechet_distance(\n",
        "    mu1=mu_gen,\n",
        "    mu2=mu_test,\n",
        "    sigma1=sigma_gen,\n",
        "    sigma2=sigma_test)\n",
        "print('FCD: ', fcd_value)\n",
        "\n",
        "validity = len(smiles_gen_can) / len(smiles_gen)\n",
        "print(\"Validity: \", validity)\n",
        "\n",
        "smiles_unique = set(smiles_gen_can)\n",
        "uniqueness = len(smiles_unique) / len(smiles_gen)\n",
        "print(\"Uniqueness: \", uniqueness)\n",
        "\n",
        "# load training set for novelty\n",
        "with open(path + \"smiles_train.txt\") as f:\n",
        "    smiles_train = {s for s in f.read().split() if s}\n",
        "\n",
        "smiles_novel = smiles_unique - smiles_train\n",
        "novelty = len(smiles_novel) / len(smiles_gen)\n",
        "print(\"Novelty: \", novelty)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FCD:  0.6926020565041426\n",
            "Validity:  1.0\n",
            "Uniqueness:  0.9987\n",
            "Novelty:  0.9229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMOxLzNOVlxP"
      },
      "source": [
        "## Load Checkpoint and proceed with training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVP2oq-C3YPv"
      },
      "source": [
        "model = MoleculeGenerator(n_in, n_hidden, n_out, n_seq, n_layers)\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=lr)   \n",
        "model, optimiser, _, dictionary = load_checkpoint(model, optimiser, epoch=10)\n",
        "model = model.to(device)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwOFEzctlK25"
      },
      "source": [
        "for epoch in range(21, 31):\n",
        "  train_error = update(model, loss, train_loader, optimiser, epoch)\n",
        "  train_errors.append(train_error)\n",
        "  valid_error = evaluate(model, loss.eval(), valid_loader, epoch)\n",
        "  valid_errors.append(valid_error)\n",
        "  save_checkpoint(model, optimiser, epoch, loss, dictionary)         "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}